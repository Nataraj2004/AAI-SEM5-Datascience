{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba50fd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python_speech_features\n",
      "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: python_speech_features\n",
      "  Building wheel for python_speech_features (setup.py): started\n",
      "  Building wheel for python_speech_features (setup.py): finished with status 'done'\n",
      "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5879 sha256=ffa717be85fe137d13210719510c6237534be1fb0070680a199278112ec759f5\n",
      "  Stored in directory: c:\\users\\mr.nataraj\\appdata\\local\\pip\\cache\\wheels\\37\\01\\19\\e6c69a32684ab7b2e3ea4985a571d810cf055c72600e7f9f17\n",
      "Successfully built python_speech_features\n",
      "Installing collected packages: python_speech_features\n",
      "Successfully installed python_speech_features-0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcdd158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed7bb2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from python_speech_features import mfcc\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/common-voice/cv-valid-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3022771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = df[df['gender']=='male']\n",
    "df_female = df[df['gender']=='female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_male.shape)\n",
    "# output: (55029, 8) \n",
    "\n",
    "print(df_female.shape\n",
    "# output: (18249, 8)\n",
    "\n",
    "# Take only 300 male and 300 female data\n",
    "df_male = df_male[:300]\n",
    "df_female = df_female[:300]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90446db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the audio path\n",
    "TRAIN_PATH = '../input/common-voice/cv-valid-train/'\n",
    "\n",
    "# The function to convert mp3 to wav\n",
    "def convert_to_wav(df, m_f, path=TRAIN_PATH):\n",
    "    srcs = []\n",
    "\n",
    "    for file in tqdm(df['filename']):\n",
    "        sound = AudioSegment.from_mp3(path+file)\n",
    "        \n",
    "\t\t# Create new wav files based on existing mp3 files\n",
    "        if m_f == 'male':\n",
    "            sound.export('male-'+file.split('/')[-1].split('.')[0]+'.wav', format='wav')\n",
    "        elif m_f == 'female':\n",
    "            sound.export('female-'+file.split('/')[-1].split('.')[0]+'.wav', format='wav')\n",
    "        \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8958d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use the convert_to_wav() function\n",
    "convert_to_wav(df_male, m_f='male')\n",
    "convert_to_wav(df_female, m_f='female')\n",
    "\n",
    "\n",
    "# Define a function to load the raw audio files\n",
    "def load_audio(audio_files):\n",
    "\t# Allocate empty list for male and female voices\n",
    "    male_voices = []\n",
    "    female_voices = []\n",
    "\n",
    "    for file in tqdm(audio_files):\n",
    "        if file.split('-')[0] == 'male':\n",
    "            male_voices.append(librosa.load(file))\n",
    "        elif file.split('-')[0] == 'female':\n",
    "            female_voices.append(librosa.load(file))\n",
    "    \n",
    "\t# Convert the list into Numpy array\n",
    "    male_voices = np.array(male_voices)\n",
    "    female_voices = np.array(female_voices)\n",
    "    \n",
    "    return male_voices, female_voices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e367f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_voices, female_voices = load_audio(os.listdir())\n",
    "\n",
    "\n",
    "# The function to extract audio features\n",
    "def extract_features(audio_data):\n",
    "\n",
    "\taudio_waves = audio_data[:,0]\n",
    "\tsamplerate = audio_data[:,1][1]\n",
    "\t\n",
    "\tfeatures = []\n",
    "\tfor audio_wave in tqdm(audio_waves):\n",
    "\t\tfeatures.append(mfcc(audio_wave, samplerate=samplerate, numcep=26))\n",
    "    \n",
    "\tfeatures = np.array(features)\n",
    "\treturn features\n",
    "\n",
    "# Use the extract_features() function\n",
    "male_features = extract_features(male_voices)\n",
    "female_features = extract_features(female_voices)\n",
    "\n",
    "\n",
    "# The function used to concatenate all audio features forming a long 2-dimensional array\n",
    "def concatenate_features(audio_features):\n",
    "    concatenated = audio_features[0]\n",
    "    for audio_feature in tqdm(audio_features):\n",
    "        concatenated = np.vstack((concatenated, audio_feature))\n",
    "        \n",
    "    return concatenated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_concatenated = concatenate_features(male_features)\n",
    "female_concatenated = concatenate_features(female_features)\n",
    "\n",
    "print(male_concatenated.shape) \t\t\n",
    "# Output: (117576, 26)\n",
    "\n",
    "print(female_concatenated.shape)\t\n",
    "# Output: (124755, 26)\n",
    "\n",
    "\n",
    "# Concatenate male voices and female voices\n",
    "X = np.vstack((male_concatenated, female_concatenated))\n",
    "\n",
    "# Create labels\n",
    "y = np.append([0] * len(male_concatenated), [1] * len(female_concatenated))\n",
    "\n",
    "# Check whether X and y are already having the exact same length\n",
    "print(X.shape)\t\t\n",
    "# Output: (242268, 26)\n",
    "\n",
    "print(y.shape)\t\t\n",
    "# Output: (242268,)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "\n",
    "# Initialize SVM model\n",
    "clf = SVC(kernel='rbf')      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "start = time()\n",
    "clf.fit(X_train[:50000], y_train[:50000])\n",
    "print(time()-start)\n",
    "# Output: 184.8018662929535 (seconds)\n",
    "\n",
    "# Compute the accuracy score towards train data\n",
    "start = time()\n",
    "print(clf.score(X_train[:50000], y_train[:50000]))\n",
    "# Output: 0.78204\n",
    "\n",
    "print(time()-start)\n",
    "# Output: 90.8693311214447 (seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f983c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy score towards test data\n",
    "start = time()\n",
    "print(clf.score(X_test[:10000], y_test[:10000]))\t\t\n",
    "# Output: 0.7679\n",
    "\n",
    "print(time()-start)\t\t\t\t\t\t\n",
    "# Output: 18.082067728042603 (seconds)\n",
    "\n",
    "\n",
    "# Predict the first 10000 test data\n",
    "svm_predictions = clf.predict(X_test[:10000])\n",
    "\n",
    "# Create the confusion matrix values\n",
    "cm = confusion_matrix(y_test[:10000], svm_predictions)\n",
    "\n",
    "# Create the confusion matrix display\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Confusion matrix on test data')\n",
    "sns.heatmap(cm, annot=True, fmt='d', \n",
    "            cmap=plt.cm.Blues, cbar=False, annot_kws={'size':14})\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Performance comparison between different algorithms\n",
    "index = ['SVM-RBF', 'SVM-Poly', 'SVM-Sigmoid', 'Logistic Regression']\n",
    "\n",
    "# I record all the results below manually\n",
    "values = [184.8, 137.0, 283.6, 0.7]\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.title('Training duration (lower is better)')\n",
    "plt.xlabel('Seconds')\n",
    "plt.ylabel('Model')\n",
    "plt.barh(index, values, zorder=2)\n",
    "plt.grid(zorder=0)\n",
    "\n",
    "for i, value in enumerate(values):\n",
    "    plt.text(value+20, i, str(value)+' secs', fontsize=12, color='black',\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc1dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.25\n",
    "    \n",
    "index = ['SVM-RBF', 'SVM-Poly', 'SVM-Sigmoid', 'Logistic Regression']\n",
    "\n",
    "# set height of bar\n",
    "# I record all the results below manually\n",
    "train_acc = [78.2, 74.8, 74.8, 65.8]\n",
    "test_acc = [76.8, 74.3, 74.3, 65.8]\n",
    " \n",
    "# Set position of bar on X axis\n",
    "baseline = np.arange(len(train_acc))\n",
    "r1 = [x + 0.125 for x in baseline]\n",
    "r2 = [x + 0.25 for x in r1]\n",
    " \n",
    "# Make the plot\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.title('Model performance (higher is better)')\n",
    "plt.bar(r1, train_acc, width=barWidth, label='Train', zorder=2)\n",
    "plt.bar(r2, test_acc, width=barWidth, label='Test', zorder=2)\n",
    "plt.grid(zorder=0)\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks([r + barWidth for r in range(len(train_acc))], index)\n",
    "\n",
    "# Create text\n",
    "for i, value in enumerate(train_acc):\n",
    "    plt.text(i+0.125, value-5, str(value), fontsize=12, color='white',\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "for i, value in enumerate(test_acc):\n",
    "    plt.text(i+0.375, value-5, str(value), fontsize=12, color='white',\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
